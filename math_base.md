# 머신러닝의 수학적 구현
## 뉴런의 모델링
### 뉴런의 모델링
머신러닝은 기본적으로 신경망의 작동구조를 모방한다. 따라서 머신러닝을 컴퓨터로 구현하기 위해서는 신경망의 작동원리를 수학적으로 모델링하는 것이 필수적이다. 신경망의 기본단위는 뉴런이므로, 신경망을 모델링하기 위해선 우선 뉴런을 모델링해야 한다.\
뉴런은 다음과 같이 모델링할 수 있다. $w_i$를 가중치(_weight_), $b$를 편향(_bias_)라고 한다.
$$
y = f_{activ}(\sum_{k=1}^nw_k x_k + b) \\
= f_{activ}(w_1x_1 + w_2x_2 + w_3x_3 + \cdots + w_nx_n + b)
$$
이렇게 모델링된 뉴런을 퍼셉트론이라고 부른다. 활성화 함수인 $f_{activ}$는 일반적으로 두 식 중 하나를 사용한다. 첫째 식은 단위계단함수로, 실제 뉴런의 활성화와 유사하지만, $x=0$ 에서 미분 불가하다는 특징을 가지고 있다. 둘째 식은 시그모이드함수로, 정의역 $\bold R$에 대해 미분이 가능하다.
$$
f_{activ}(x) = 
\begin{cases}
1,\; x > 0 \\
0,\; x < 0
\end{cases} \\
f_{activ}(x) = 
\frac{1}{1 + e^{-x}}
$$
딥러닝은 이와 같이 모델링된 뉴런들을 다중 레이어에 배치하여 구현한다.
### 벡터
뉴런의 수학적 모델링은 이와 같이 표현가능하지만, 더 간편한 표현을 위해 벡터와 행렬을 사용한다. 벡터는 기저의 실수배의 합을 통해 정의된다. 기저는 벡터공간을 선형생성하는, 선형독립인 단위벡터로 정의한다. 쉽게 표현하면, 임의의 $N$차원 공간의 $x$축, $y$축과 같은 축의 양의 방향을 가지는, 크기가 1인 벡터이다. 기저는 $\overrightarrow{e_1},\;\overrightarrow{e_2},\;\cdots,\;\overrightarrow{e_n}$과 같이 표현한다. 벡터는 기저들의 실수배의 합으로 정의된다. 가령 벡터$\overrightarrow{v}$의 시점이 $(0, 0)$이고, 종점이 $(3, 2)$일 때, 벡터 $\overrightarrow{v}$는 다음과 같이 표현가능하다.
$$
\overrightarrow{v} = 3\overrightarrow{e_1} + 2\overrightarrow{e_2}=\;<3, 2>
$$

## 회귀분석
회귀분석은 변수 혹은 변수들(_feature_)과 다른 한 변수(_target_)의 관계를 분석하는 통계적 기법이다. 회귀분석은 머신러닝에서 광범위하게 쓰이지만, 그 중 신경망 학습에 쓰이는 선형회귀에 대해서 설명하겠다.

### 경사하강법
