---
title: 기계는 생각할 수 있는가?
feed: show
date: 04-04-2024
mathjax: true
---

## 기계는 생각할 수 있는가 (Can machine think) ?

> 본 리포트는 융합뇌공학입문(ENG2009) 기말 리포트 제출본임.

기계가 생각할 수 있는가에 대한 질문에 대해 대답하기 위해서는 생각과 의식을 적절하게 정의해야 한다. 일상에서 생각의 범주는 넓으면서도 추상적이다. 추론, 계획, 상상 등 다양한 사고 활동을 생각이라고 부른다. 하지만 단순하게 생각의 후보들을 나열하고 나열된 대상들을 통칭해 생각이라고 부르는 것은 생각에 대한 논증에서도 번거로울 뿐만 아니라 그리 만족스러운 답을 얻을 가능성도 적을 것이다.


인간의 사고만을 생각의 유일한 사례로 정의하는 것은 그리 흥미롭지 못하다. 인간의 지능은 절대적인 것이 아니다. 인간이 자연 속에 존재하는 생명체 중에서는 가장 높은 지능을 가지고 있기 때문에 간과하는 사실이지만, 인간의 지능 또한 지능의 한 예시일 뿐 지능의 가장 일반적이고 표준적인 형태라고는 볼 수 없기 때문이다. 인간의 사고는 실제로도 사고의 일반화된 형태라고 보기 힘든 특징들을 가지고 있다. 인간의 뇌는 익숙한 특징들을 외부에 투사하여 대상을 인식하는 경향이 있으며, 가용성 휴리스틱(Tversky et al., 1973), 대표성 휴리스틱(Tversky et al., 1974)와 같은 휴리스틱을 주로 사용하여 사고한다. 한편 인간은 느린 사고와 같이 다른 방식의 사고 또한 수행할 수 있다. 이 두 가지 서로 다른 방식의 사고는 분명하게 구분되고 한 가지의 사고만 할 수 있다고 해서 그것을 생각이라고 부르지 못할 이유는 없다. 따라서 적어도 인간의 사고는 생각의 유일한 예시가 될 수 없다.


그러므로 인간의 사고를 모방하는 데만 몰두하는 것은 그리 적절한 접근이 아니다. 예를 들기 위해 인간의 지능을 모나리자와 같은 하나의 예술작품에 비유해보자. 모나리자는 분명 훌륭한 예술작품이지만, 모나리자가 예술의 일반화된 형태라고 볼 수는 없다. 모나리자를 모방하고 복제하는 데만 몰두하는 것은 예술의 본질에 다가간다고 보기도 어려울 것이고, 모나리자를 복제할 수 있다고 해서 다빈치의 예술적 감각과 창작능력을 습득했다고 할 수도 없을 것이다. 따라서 지능과 생각의 일반화된 정의에 대해 먼저 고민해봐야 한다. 그렇다면 어떻게 지능과 생각을 정의하는 것이 좋을까?


인간이 다루는 모든 것은 정보로 치환 가능하다는 것에서 힌트를 얻을 수 있을 것이다. 인간은 여러 감각질, 지향성을 정보를 인식하고 표현할 뿐만 아니라, 정보를 처리하고, 새로운 정보를 추론하기도 한다. 다만 주의해야 할 것은 인간의 사고를 이성과 감성으로 구분하고 이성에 대해서만 논해서는 것이 아니라는 것이다. 인간의 정보처리는 이성적으로만 작용하지 않으며, 휴리스틱 방법, 감정적인 방법들을 모두 사용한다. 일상 속에서도 인간은 스스로 합리적이고 이성적으로 판단한다고 여기지만 실제로는 감성에 따라 판단하는 경우가 많다. (Finucane et al., 2000)


이성과 감성의 이분법적 구분은 다소 자의적이다. 인간은 스스로가 이성적 사고와 감성적 판단을 구분할 수 있다고 생각할 수 있지만 그렇지 않다. 감성과 이성은 매우 많은 의사결정에 동시에 관여하며, 이 둘을 구분하는 것은 매우 어렵다. 아이오와 도박 과제 연구(Bechara et al. 1997)에 따르면 어떤 결정에 대한 손익을 의식적으로, 이성적으로 구분하지 못하는 단계에서도 교감신경은 무의식 중에 유리한 선택을 유도했다. 의사결정 과정에서 인간은 과거 유사한 경험들에 대한 정서를 느끼고 이는 의사결정에 반영된다. 따라서 인간의 정신활동을 이성과 감성으로 구분하고, 생각을 이성으로만 정의하는 것은 자의적인 구분이 될 수 있으며, 실체를 잘 반영하지 못할 수 있다.


그렇다면 인간의 정신활동을 정보 처리로 환원가능한가의 문제가 생긴다. 우선 추론, 인과관계 파악과 같은 고차원적, 추상적 정신활동은 정보 처리로 환원 가능할 것이다. 인간의 대부분의 이성적 사고 과정은 언어, 수식과 같은 기호체계로 환원가능하고, 명시적 정보처리가 가능하기 때문이다. 그렇다면 정서 또한 정보처리로 환원 가능할지 살펴봐야 한다. 정서는 주로 피질하 영역에서 작용한다. 가령 공포는 편도체에서 작용하며, 더러움에 관한 정서는 섬엽에서 관여한다. 뇌의 보상체계는 흑질에서 기인한다. 비록 정서를 기호체계로 환원시키는 것은 어려울 수 있지만 정서 또한 정보 처리의 일환으로 볼 수 있다. 외부 자극이 시상을 통해 기저핵으로 전달되면 이에 따라 정서반응이 발생한다. 가령 방울뱀 형체를 봤을 때, 안구의 신호는 시상을 통해 편도체로 이동하고 공포라는 정서를 발생시킨다. (LeDoux, 1996) 따라서 인간의 대부분의 정신활동은 정보처리로 환원 가능하다. 그러므로 생각은 정보의 처리, 즉 정보의 변환과 부호화로 환원 가능하다고 할 수 있을 것이다.


그렇다면 기계, 컴퓨터의 정보처리와 인간의 정보처리는 무엇이 다른 것일까? 분명히 컴퓨터는 정보를 변환하고 부호화할 수 있는 능력이 있다. ChatGPT와 같은 거대 언어 모델(LLM)들은 과거 인간만의 영역이라고 여겨왔던 것들을 충분히 잘 수행한다. 대부분의 LLM들은 Self-Attention Layer로만 구성되어 있어(Brown et al., 2020; Zhang et al., 2020; Ouyang et al., 2022), 기저핵, 해마와 같은 영역을 가지고 있지는 않다. 따라서 인간과 같은 메커니즘으로 정보를 변환하거나 부호화시키지는 못할 것이다. 하지만 인간의 언어능력을 충분히 잘 모방한다. 여러 데이터를 통해 학습한 지식들을 파라미터에 저장하며, 이를 적절하게 인출해 텍스트를 생성한다. 또한 인간이 망각을 하듯 모델의 학습 과정에서 새로운 정보가 계속 들어올 때는 Catastrophic forgetting이 발생한다. (McCloskey et al., 1989) 이는 딥러닝 모델이 데이터에서 일반화된 지식을 습득하고, 이를 파라미터 속에 표상함을 의미한다고 볼 수 있다. 인간의 방식과는 다르지만, 정보의 변환과 부호화가 딥러닝 모델의 방식대로 일어난다고 할 수 있을 것이다.


하지만 여전히 LLM의 수준은 인간에 미치지 못하는 것 같다. 인간은 매 순간마다 외부와 상호작용하면서 신경망의 연결이 변화하여 새로운 지식과 정보를 습득하는 반면, 딥러닝 모델은 Training 과정에서만 신경망, 파라미터의 상태가 변화하며, Inference 단계에서는 파라미터가 변화하지 않는다. 이는 정신 작용에 있어서 많은 차이를 만들어낼 것이다. 또한 이전 어절(토큰)들의 시퀀스들을 바탕으로 다음 토큰에 대한 확률분포를 반환하는 LLM의 작동방식은 신경상태가 시간속에서 작동하며 언어를 생성해내는 인간의 작동방식과는 매우 달라 보인다. LLM은 언어를 생성해내는 매 단계마다 연속된 내부 상태를 가지지 않고, 이전에 생성된 텍스트들 만을 바탕으로 일정 기준에 맞게 적절한 다음 말들에 대한 확률분포를 반환한다. 그 후 반환된 확률분포에서 일정 규칙에 따라 다음에 나올 알맞은 말을 샘플링한다. 시간적 흐름 속에서 사고과정을 통해 언어를 생성하는 것이 아니라, 그저 이전의 텍스트들을 바탕으로 다음에 올 적절한 어절을 선택하는 것에 불과하다는 것이다.


생각을 정보의 변환과 부호화만으로 정의했을 때는 이러한 차이에 대한 만족스러운 설명을 제시하기 힘들다. 인간은 여러 감각기관을 입력으로 받아 뇌 내의 여러 기관에서 기존의 정보들을 바탕으로 정보를 산출, 생성해내고, LLM은 Self-Attention Layer에서 정보의 변환과 부호화가 일어난다는 차이만이 존재하기 때문이다. 따라서 정보 처리의 관점에서는 인간과 LLM사이에 존재하는 본질적인 차이를 설명하지 못한다. 이에 대해 만족스러운 답을 하기 위해서는 두 대상이 차이를 보이는 다른 성질에 대해 확인해봐야 한다.


의식은 인간과 딥러닝 모델이 가지는 가장 큰 차이로 볼 수 있을 것이다. 비록 다른 마음의 존재 여부에 대해 알지는 못하지만 의식을 가진다고 보기는 어렵다. 의식은 사고의 과정을 인식하는 것을 포함한다. 의식은 정보의 변환과정을 인식하는 것을 필요조건으로 가지고 있다는 것이다. 하지만 LLM을 포함한 대부분의 딥러닝 모델은 정보의 변환과정을 인식할 수 없을 것이다. Transformer 모델의 inference 과정에서 각 Layer에서는 들어오는 입력이 어떤 변환과정을 거친 정보인지 확인할 여지가 없기 때문이다. 따라서 딥러닝 모델은 의식이 없다고 보는 것이 합리적이다.


컴퓨터가 의식을 가질 수 있는지에 대해 검증하기 전에 우선 의식이 생각의 필요조건인지 확인할 필요가 있다. 앞서 생각은 정보처리로 정의되었다. 꼭 딥러닝 모델이 아니더라도 컴퓨터는 여러 알고리즘을 실행해 정보를 처리한다. 의식에 기반한 정보처리와 의식이 없는 정보처리가 다른 것이 무엇일까? 우선 의식은 _생각하고 있는 것_ 에 대해 생각한다는 특징이 있다. 인간은 자기 자신이 무엇에 대해 생각하고 있는지 인지할 수 있고, 이를 기반으로 생각의 방향을 적절하게 조정한다. 현재의 마음 상태를 인식하고, 마음 상태를 하나의 정보로 다루어 처리가 가능하다는 것이다. 그렇기 때문에 주어진 일을 하더라도 우직하게 주어진 일을 하나하나 따르지 않고, 자의적으로 스스로의 수행과정을 되돌아 살펴보고 수행의 개선 방향을 모색하는 것이 가능하다. 정보를 정보로 인식할 수 있다는 것이다.


반면 컴퓨터는 그렇지 않다. 컴퓨터가 컴퓨터의 현재 상태를 처리하는 것은 부분적으로는 가능하지만, 계산 명령이 현재 상태를 확인하도록 짜여진 경우일 뿐이다. 결국 컴퓨터는 주어진 계산 명령을 순차적으로 실행할 뿐, 실행하는 계산 과정 자체에 대해서는 처리하지 못한다. 그렇기 때문에 컴퓨터의 연산은 정보를 정보로써 다루는 것이 아닌, 단순히 물리법칙에 따른 동작에 불과하다. 물시계 속에서 물이 흘러 시간을 표상한다고 해서 물시계가 시간을 인지하고 있는 것이 아니듯이, 컴퓨터는 컴퓨터 속에 저장된 전자를 인식하지 못한다. 스스로의 처리과정을 처리 대상으로 인지하고 스스로의 처리과정을 계획할 수 있는 능력은 인간의 생각과 기계의 연산이 보이는 큰 차이이다.


앞서 서술했듯, 처리과정에 대한 인지는 전통적인 대부분의 컴퓨터 동작과 인간이 보이는 대표적인 차이였다. 하지만 컴퓨터의 표상능력을 간과해서는 안 된다. 인간은 인간의 뇌 동작을 의식적으로 인식하지 못한다. 하지만 뇌의 표상이 의식을 구현하는 것처럼, 컴퓨터의 연산과정 자체는 의식적이지 않아도 컴퓨터가 의식을 표상할 수도 있기 때문이다.


이제 본격적으로 컴퓨터가 의식을 구현할 수 있는지에 대해 확인할 필요가 있다. 의식에 관해서는 많은 논의가 진행되었고, 의식이 어떻게 구현되는지는 명확히 밝혀지지 않았다. 차머스는 이를 일컬어 신경 작용 법칙을 밝혀내는 것은 쉬운 문제이지만, 의식이 어떻게 구현되는지는 어려운 문제에 해당한다고 주장하기도 했다. 하지만 이 문제에 대해 존 설의 논증에서 힌트를 얻을 수 있을 것이다. 존 설은 파리스가 세 여신에게 황금사과를 주는 것을 고민할 때 의식이 시간속에 고정되었다고 말했다. 의식상태는 시간 속에 고정되어 신경상태가 변화하는 과정에서 결정된다. 의식상태는 미시적인 신경상태가 표상하는 성질로 볼 수 있는 것이다. 만약 신경상태가 의식을 구현한다고 한다면, 컴퓨터가 의식을 구현하지 못할 이유는 없다. 딥러닝 모델 내에서도 한 Layer 내에서 입력과 파라미터의 곱으로 새로운 값을 계산하고 이를 다음 Layer에 입력으로 출력함으로써 순차적인 정보의 변환과정을 구현하는 것이 가능하다. 그저 모델의 아키텍처가 적절하지 못하고 규모가 동물 수준보다 작기 때문에 구현하지 못하는 것일 뿐이다.


컴퓨터가 의식을 구현할 수 있다고 해도 인간과는 다른 방식으로 사고할 가능성이 크다. 인간의 의식에 대한 주관적인 경험을 컴퓨터가 그대로 구현하기는 힘들 것이기 때문이다. 하지만 인간의 뇌는 일종의 pre-trained model이다. DNA에 뇌의 전반적인 구성이 저장되어 있고, 부호화된 유전정보가 발달 과정에서 단백질로 번역되어 형질이 발현하는 것이기 때문이다. 이렇게 형성된 뇌 속에서 발생하는 주관적 경험은 일인칭적 존재론에 속하는 것이고, 이를 삼인칭적 존재론으로 환원시킬 수는 없다. 그렇기 때문에 컴퓨터가 이렇게 구성된 인간 사고의 주관적 경험을 모방하여 구현하는 것은 매우 어려울 것이다. 물론 겉으로 드러나는 인간의 여러 특징들을 모방하도록 할 수는 있겠지만, 이는 호박에 줄을 긋는 일 밖에 되지 않을 것이다. 하지만 이것이 컴퓨터가 생각하지 못한다는 것을 의미하는 것은 아니다. 인간의 지능은 보편적 지능이 아니기 때문이다. 구현된 기계는 기계의 방식으로, 인간은 인간의 방식으로 생각과 의식을 구현하는 것일 뿐이다. 그것이 기계는 생각할 수 없다는 것을 함축하지는 못한다.

### Reference

Tversky, A., & Kahneman, D. (1973). Availability: A heuristic for judging frequency and probability. Cognitive psychology, 5(2), 207-232.

Tversky, A., & Kahneman, D. (1974). Judgment under Uncertainty: Heuristics and Biases: Biases in judgments reveal some heuristics of thinking under uncertainty. science, 185(4157), 1124-1131.

Finucane, M. L., Alhakami, A., Slovic, P., & Johnson, S. M. (2000). The affect heuristic in judgments of risks and benefits. Journal of behavioral decision making, 13(1), 1-17.

Bechara, A., Damasio, H., Tranel, D., & Damasio, A. R. (1997). Deciding advantageously before knowing the advantageous strategy. Science, 275(5304), 1293-1295.

LeDoux, J. (1996). Emotional networks and motor control: a fearful view. Progress in brain research, 107, 437-446.

Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., ... & Amodei, D. (2020). Language models are few-shot learners. Advances in neural information processing systems, 33, 1877-1901.

Zhang, J., Zhao, Y., Saleh, M., & Liu, P. (2020, November). Pegasus: Pre-training with extracted gap-sentences for abstractive summarization. In International Conference on Machine Learning (pp. 11328-11339). PMLR.

Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., ... & Lowe, R. (2022). Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems, 35, 27730-27744.

McCloskey, M., & Cohen, N. J. (1989). Catastrophic interference in connectionist networks: The sequential learning problem. In Psychology of learning and motivation (Vol. 24, pp. 109-165). Academic Press.