<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/_next/static/css/e7828a7281941fdd.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-7873f912334caea6.js"/><script src="/_next/static/chunks/fd9d1056-f5ca11604835b0e5.js" async=""></script><script src="/_next/static/chunks/23-e56a11d2b39fa54e.js" async=""></script><script src="/_next/static/chunks/main-app-25a28da902dbdb74.js" async=""></script><script src="/_next/static/chunks/231-c5de4feaddc0b512.js" async=""></script><script src="/_next/static/chunks/app/layout-6c2c9e9b413bbfd5.js" async=""></script><title>SOL1 Archive</title><meta name="description" content="Personal Research Blog"/><link rel="icon" href="/favicon.ico"/><script src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body><main class="min-h-screen bg-background text-foreground flex flex-col"><div class="GlassContainer_glass__BAl5w TopBar_topBar__6dGjo"><div class="TopBar_container__PF96i"><div><a class="TopBar_brandLink__ialkS" href="/">SOL1 Archive</a></div><nav class="TopBar_nav__245RK"><a class="TopBar_navLink__cN8l7 " href="/">Home</a><a class="TopBar_navLink__cN8l7 " href="/posts">Posts</a></nav><div class="TopBar_actions__aM8Lf"><a href="https://github.com/SOL1archive" target="_blank" rel="noopener noreferrer" class="TopBar_iconLink___D8mn" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-github"><path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"></path><path d="M9 18c-4.51 2-5-2-7-2"></path></svg></a><a href="https://linkedin.com/in/subinbag" target="_blank" rel="noopener noreferrer" class="TopBar_iconLink___D8mn" aria-label="LinkedIn"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-linkedin"><path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path><rect width="4" height="12" x="2" y="9"></rect><circle cx="4" cy="4" r="2"></circle></svg></a><a href="/cv/resume.pdf" download="" class="TopBar_iconLink___D8mn" aria-label="Download CV"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text"><path d="M14.5 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7.5L14.5 2z"></path><polyline points="14 2 14 8 20 8"></polyline><line x1="16" x2="8" y1="13" y2="13"></line><line x1="16" x2="8" y1="17" y2="17"></line><line x1="10" x2="8" y1="9" y2="9"></line></svg></a><button class="TopBar_iconLink___D8mn" aria-label="Toggle Dark Mode"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-sun"><circle cx="12" cy="12" r="4"></circle><path d="M12 2v2"></path><path d="M12 20v2"></path><path d="m4.93 4.93 1.41 1.41"></path><path d="m17.66 17.66 1.41 1.41"></path><path d="M2 12h2"></path><path d="M20 12h2"></path><path d="m6.34 17.66-1.41 1.41"></path><path d="m19.07 4.93-1.41 1.41"></path></svg></button></div></div></div><div class="flex-1 w-full max-w-[1200px] mx-auto p-8"><div class="page_layout__YXtDc"><div class="GlassContainer_glass__BAl5w page_postContainer__8rQn1"><article><header class="page_header__LPYYk"><h1 class="page_title__Tljh5">Autoencoder와 공간주파수</h1><div class="page_meta__FlrbA"><time>04-04-2023</time></div></header><div class="page_content__kgYnh"><p>AutoEncoder는 신경망 시퀀스 중앙에 Bottle Neck이 존재하고, Bottle Neck을 중심으로 대칭적인 구조를 가진 딥러닝 모델을 가리킨다. FFNN뿐만 아니라 LSTM과 같은 RNN Family, CNN, Transformer 등 다양한 신경망 기본 아키텍처로 AutoEncoder를 구현할 수 있다. AutoEncoder는 Anomaly Detection과 Noise Reduction에서 뛰어난 성능을 발휘한다. AutoEncoder의 학습은 Bottle Neck을 기준으로 입력 방향의 Encoder 부분과 출력 방향의 Decoder 부분이 같이 이루어진다. Encoder와 Decoder는 입력 데이터를 최대한 동일하게 출력하도록 학습된다. 일반적인 형태의 신경망에서는 이것이 어렵지 않다. 하지만 AutoEncoder의 Encoder와 Decoder 사이에 위치한 Bottle Neck으로 인해 Encoder에서 Decoder로 전달할 수 있는 정보의 양은 한계가 있다. 때문에 일반적으로 Encoder가 입력 데이터의 정보를 온전하게 Decoder로 전달하기는 매우 어렵다. 그렇기 때문에 학습과정에서 Encoder는 의미있는 정보만을 최대한 압축해서 Bottle Neck을 통해 Decoder로 보낸다. 이때 정보는 일반적으로 벡터로 표현되거나 벡터와 동형(<em>isomorphic</em>)인 대상이기 때문에 압축된 정보의 벡터공간을 내부공간(<em>Latent Space</em>)이라 한다. 입력 데이터가 Latent Space로 사상(<em>map</em>)하는 것이다. Decoder는 이렇게 건내받은 정보를 최대한 입력 데이터와 같도록 학습된다.</p>
<p>AutoEncoder는 압축 기술 뿐만 아니라 Anomaly Detection과 Noise Reduction에서 뛰어난 성능을 가진다. Anomaly Detection은 비정상 신호를 감지하는 분야를 말한다. Noise Reduction은 입력 데이터에서 잡음만을 최대한 제거하고 신호만을 얻도록 하는 분야이다. AutoEncoder는 단순히 내부 공간에 데이터를 표현했을 뿐인데 어떻게 이것이 가능할까? 이는 신경과학적인 관점에서 이해될 수 있다.</p>
<p>신경과학에서는 공간주파수(<em>Spatial Frequency</em>)라는 개념이 있다. 공간주파수란 신호를 어떤 주파수로 표현하는지에 대한 개념이다. 낮은 공간주파수로 신호가 표현되면 적은 신호만을 표현할 수 있다. 반면에 높은 공간주파수로 신호가 표현되면 많은 정보를 표현할 수 있다. 4G 통신에 사용되는 전파의 주파수가 5G 통신에 사용되는 주파수보다 더 낮아 한번에 더 적은 정보만을 전달할 수 있는 것, 사용되는 주파수가 더 높은 FM라디오의 음질이 주파수가 낮은 AM라디오의 음질보다 더 좋은 것을 생각하면 쉽게 이해할 수 있다. 생물체의 신경망은 낮은 공간주파수와 높은 공간 주파수를 동시에 사용하여 정보를 표현하고 처리한다. 낮은 공간주파수에선 적은 정보만 표현이 가능하므로 대략적이고 포괄적인 정보만을 표현한다. 반면, 높은 공간주파수에서는 더 많은 정보를 표현할 수 있으므로 정보를 세밀하게 표현한다. 대략적인 정보만을 표현하는 것보다 세밀한 정보까지 같이 표현하는 것이 언제나 더 좋아보임에도 이를 사용하는 이유는 다음 그림으로 이해할 수 있다.</p>
<p><img src="https://www.researchgate.net/profile/H-Scholte/publication/258350831/figure/fig3/AS:340788283232259@1458261666232/Example-of-a-face-with-all-spatial-frequency-information-allSF-only-low-spatial.png" alt=""></p>
<p>[Fig 1. Spatial Frequency. Image from <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0076467">Jahfari S et al, 2013</a>]</p>
<p>allSF는 모든 영역에서의 Spatial Frequency, 즉 공간주파수를 표현한 것이고 LSF는 Low Spatial Frequency, HSF는 High Spatial Frequency를 나타낸 것이다. 앞서 설명했다시피 LSF에서는 대략적인 정보만을, HSF에서는 세부적인 정보까지 표현하고 있음을 알 수 있다. 그렇기 때문에 낮은 공간주파수에서 높은 공간 주파수에서보다 <strong>웃는다</strong>는 특징이 더 잘 나타난다. 여기서 낮은 공간주파수의 장점이 나타난다. 대략적인 정보만을 표현하기 때문에 정보에서 전반적인 특징이 더 두드러지게 나타나는 것이다.</p>
<p>전반적인 특징이 강조되고 세부적인 특징은 무시됨으로써 정보 처리의 효율성을 높일 수 있다. 필요없는 세부정보와 여러 오차로 인해 발생한 잘못된 정보(잡음)이 무시되어 정보의 중요한 특징이 강조되어 나타난다. 이렇게 표현된 정보의 양은 상대적으로 적기 때문에 정보 처리 비용도 더욱 줄어든다. 그리고 정보의 전체적인 특징을 더 잘 드러내기 때문에 정보의 파악에도 유리하다. 가령 Fig 1에서 웃는 표정이 슬픈 표정으로 바뀌었을 때 낮은 공간주파수(LSF) 표현에서 높은 공간주파수(HSF)에서보다 더 쉽게 변화를 파악할 수 있을 것이다. 또한 실제 세계에서의 여러 요인으로 인해 신호에 잡음이 발생하여 corruption되었을 때, 높은 공간주파수에서는 이에 대한 영향을 크게 받겠지만 낮은 공간주파수로 표현된 정보는 이에 대한 영향을 적게 받을 것이다. 정보 처리의 안정성이 높아지는 것이다.</p>
<p>이러한 이유로 인해 인간의 시각 중 주변시에 대해서는 신경수렴이 발생하여 낮은 공간주파수로 신호가 표현되고 중앙시는 높은 공간주파수로 신호가 표현된다. 인간은 주변시에 적은 신경처리자원을, 중앙시에 많은 신경처리자원을 배분하여 주변시는 적은 신경처리자원으로 최대한 효율적인 정보처리를하고 시선의 중심에 위치한 중앙시에 대해서는 세밀한 정보처리를 수행한다. 또 주의(<em>Attention</em>)을 이용해 주의의 대상은 높은 공간주파수로, 이외의 대상은 낮은 공간주파수로 표현한다.</p>
<p>AutoEncoder는 이러한 신경과학적 특징을 활용했다고 볼 수 있다. AutoEncoder의 Encoder는 입력 정보를 적은 정보량으로 표현하기 때문에(낮은 공간주파수에 표현하기 때문에) 불필요하거나 잡음으로 인해 훼손된 세부적인 정보를 무시하고 전체적인 특징만을 쉽게 파악할 수 있도록 한다. 이것이 AutoEncoder가 Anomaly Detection과 Noise Reduction에서 좋은 성능을 보이는 이유일 것이다.</p>
<h4 id="reference">Reference</h4>
<p><a href="https://doi.org/10.1371/journal.pone.0076467">Jahfari S, Ridderinkhof KR, Scholte HS (2013) Spatial Frequency Information Modulates Response Inhibition and Decision-Making Processes. PLoS ONE 8(10): e76467.</a></p></div></article></div><aside class="page_sidebar__vVJp_"><nav class="TOC_toc__LZ8ns"><h4 class="TOC_title__k1O4v">On This Page</h4><ul class="TOC_list__jQuW3"><li class="TOC_item__f3x9l TOC_level-4__ZEwea"><a href="#reference">Reference</a></li></ul></nav></aside></div></div></main><script src="/_next/static/chunks/webpack-7873f912334caea6.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/css/e7828a7281941fdd.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"2:I[5751,[],\"\"]\n5:I[9275,[],\"\"]\n7:I[1343,[],\"\"]\n8:I[3889,[\"231\",\"static/chunks/231-c5de4feaddc0b512.js\",\"185\",\"static/chunks/app/layout-6c2c9e9b413bbfd5.js\"],\"default\"]\n9:I[1254,[\"231\",\"static/chunks/231-c5de4feaddc0b512.js\",\"185\",\"static/chunks/app/layout-6c2c9e9b413bbfd5.js\"],\"default\"]\nb:I[6130,[],\"\"]\n6:[\"slug\",\"Public/AutoEncoder-spatial-frequency\",\"c\"]\nc:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/e7828a7281941fdd.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L2\",null,{\"buildId\":\"XyTXgP6qMgUjdp3ye3Nwy\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/Public/AutoEncoder-spatial-frequency\",\"initialTree\":[\"\",{\"children\":[[\"slug\",\"Public/AutoEncoder-spatial-frequency\",\"c\"],{\"children\":[\"__PAGE__?{\\\"slug\\\":[\\\"Public\\\",\\\"AutoEncoder-spatial-frequency\\\"]}\",{}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[[\"slug\",\"Public/AutoEncoder-spatial-frequency\",\"c\"],{\"children\":[\"__PAGE__\",{},[[\"$L3\",\"$L4\"],null],null]},[\"$\",\"$L5\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"$6\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L7\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"children\":[\"$\",\"main\",null,{\"className\":\"min-h-screen bg-background text-foreground flex flex-col\",\"children\":[[\"$\",\"$L8\",null,{\"gaId\":\"\"}],[\"$\",\"$L9\",null,{}],[\"$\",\"div\",null,{\"className\":\"flex-1 w-full max-w-[1200px] mx-auto p-8\",\"children\":[\"$\",\"$L5\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L7\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"notFoundStyles\":[],\"styles\":null}]}]]}]}]}],null],null],\"couldBeIntercepted\":false,\"initialHead\":[false,\"$La\"],\"globalErrorComponent\":\"$b\",\"missingSlots\":\"$Wc\"}]]\n"])</script><script>self.__next_f.push([1,"d:T1ae0,"])</script><script>self.__next_f.push([1,"\u003cp\u003eAutoEncoder는 신경망 시퀀스 중앙에 Bottle Neck이 존재하고, Bottle Neck을 중심으로 대칭적인 구조를 가진 딥러닝 모델을 가리킨다. FFNN뿐만 아니라 LSTM과 같은 RNN Family, CNN, Transformer 등 다양한 신경망 기본 아키텍처로 AutoEncoder를 구현할 수 있다. AutoEncoder는 Anomaly Detection과 Noise Reduction에서 뛰어난 성능을 발휘한다. AutoEncoder의 학습은 Bottle Neck을 기준으로 입력 방향의 Encoder 부분과 출력 방향의 Decoder 부분이 같이 이루어진다. Encoder와 Decoder는 입력 데이터를 최대한 동일하게 출력하도록 학습된다. 일반적인 형태의 신경망에서는 이것이 어렵지 않다. 하지만 AutoEncoder의 Encoder와 Decoder 사이에 위치한 Bottle Neck으로 인해 Encoder에서 Decoder로 전달할 수 있는 정보의 양은 한계가 있다. 때문에 일반적으로 Encoder가 입력 데이터의 정보를 온전하게 Decoder로 전달하기는 매우 어렵다. 그렇기 때문에 학습과정에서 Encoder는 의미있는 정보만을 최대한 압축해서 Bottle Neck을 통해 Decoder로 보낸다. 이때 정보는 일반적으로 벡터로 표현되거나 벡터와 동형(\u003cem\u003eisomorphic\u003c/em\u003e)인 대상이기 때문에 압축된 정보의 벡터공간을 내부공간(\u003cem\u003eLatent Space\u003c/em\u003e)이라 한다. 입력 데이터가 Latent Space로 사상(\u003cem\u003emap\u003c/em\u003e)하는 것이다. Decoder는 이렇게 건내받은 정보를 최대한 입력 데이터와 같도록 학습된다.\u003c/p\u003e\n\u003cp\u003eAutoEncoder는 압축 기술 뿐만 아니라 Anomaly Detection과 Noise Reduction에서 뛰어난 성능을 가진다. Anomaly Detection은 비정상 신호를 감지하는 분야를 말한다. Noise Reduction은 입력 데이터에서 잡음만을 최대한 제거하고 신호만을 얻도록 하는 분야이다. AutoEncoder는 단순히 내부 공간에 데이터를 표현했을 뿐인데 어떻게 이것이 가능할까? 이는 신경과학적인 관점에서 이해될 수 있다.\u003c/p\u003e\n\u003cp\u003e신경과학에서는 공간주파수(\u003cem\u003eSpatial Frequency\u003c/em\u003e)라는 개념이 있다. 공간주파수란 신호를 어떤 주파수로 표현하는지에 대한 개념이다. 낮은 공간주파수로 신호가 표현되면 적은 신호만을 표현할 수 있다. 반면에 높은 공간주파수로 신호가 표현되면 많은 정보를 표현할 수 있다. 4G 통신에 사용되는 전파의 주파수가 5G 통신에 사용되는 주파수보다 더 낮아 한번에 더 적은 정보만을 전달할 수 있는 것, 사용되는 주파수가 더 높은 FM라디오의 음질이 주파수가 낮은 AM라디오의 음질보다 더 좋은 것을 생각하면 쉽게 이해할 수 있다. 생물체의 신경망은 낮은 공간주파수와 높은 공간 주파수를 동시에 사용하여 정보를 표현하고 처리한다. 낮은 공간주파수에선 적은 정보만 표현이 가능하므로 대략적이고 포괄적인 정보만을 표현한다. 반면, 높은 공간주파수에서는 더 많은 정보를 표현할 수 있으므로 정보를 세밀하게 표현한다. 대략적인 정보만을 표현하는 것보다 세밀한 정보까지 같이 표현하는 것이 언제나 더 좋아보임에도 이를 사용하는 이유는 다음 그림으로 이해할 수 있다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://www.researchgate.net/profile/H-Scholte/publication/258350831/figure/fig3/AS:340788283232259@1458261666232/Example-of-a-face-with-all-spatial-frequency-information-allSF-only-low-spatial.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e[Fig 1. Spatial Frequency. Image from \u003ca href=\"https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0076467\"\u003eJahfari S et al, 2013\u003c/a\u003e]\u003c/p\u003e\n\u003cp\u003eallSF는 모든 영역에서의 Spatial Frequency, 즉 공간주파수를 표현한 것이고 LSF는 Low Spatial Frequency, HSF는 High Spatial Frequency를 나타낸 것이다. 앞서 설명했다시피 LSF에서는 대략적인 정보만을, HSF에서는 세부적인 정보까지 표현하고 있음을 알 수 있다. 그렇기 때문에 낮은 공간주파수에서 높은 공간 주파수에서보다 \u003cstrong\u003e웃는다\u003c/strong\u003e는 특징이 더 잘 나타난다. 여기서 낮은 공간주파수의 장점이 나타난다. 대략적인 정보만을 표현하기 때문에 정보에서 전반적인 특징이 더 두드러지게 나타나는 것이다.\u003c/p\u003e\n\u003cp\u003e전반적인 특징이 강조되고 세부적인 특징은 무시됨으로써 정보 처리의 효율성을 높일 수 있다. 필요없는 세부정보와 여러 오차로 인해 발생한 잘못된 정보(잡음)이 무시되어 정보의 중요한 특징이 강조되어 나타난다. 이렇게 표현된 정보의 양은 상대적으로 적기 때문에 정보 처리 비용도 더욱 줄어든다. 그리고 정보의 전체적인 특징을 더 잘 드러내기 때문에 정보의 파악에도 유리하다. 가령 Fig 1에서 웃는 표정이 슬픈 표정으로 바뀌었을 때 낮은 공간주파수(LSF) 표현에서 높은 공간주파수(HSF)에서보다 더 쉽게 변화를 파악할 수 있을 것이다. 또한 실제 세계에서의 여러 요인으로 인해 신호에 잡음이 발생하여 corruption되었을 때, 높은 공간주파수에서는 이에 대한 영향을 크게 받겠지만 낮은 공간주파수로 표현된 정보는 이에 대한 영향을 적게 받을 것이다. 정보 처리의 안정성이 높아지는 것이다.\u003c/p\u003e\n\u003cp\u003e이러한 이유로 인해 인간의 시각 중 주변시에 대해서는 신경수렴이 발생하여 낮은 공간주파수로 신호가 표현되고 중앙시는 높은 공간주파수로 신호가 표현된다. 인간은 주변시에 적은 신경처리자원을, 중앙시에 많은 신경처리자원을 배분하여 주변시는 적은 신경처리자원으로 최대한 효율적인 정보처리를하고 시선의 중심에 위치한 중앙시에 대해서는 세밀한 정보처리를 수행한다. 또 주의(\u003cem\u003eAttention\u003c/em\u003e)을 이용해 주의의 대상은 높은 공간주파수로, 이외의 대상은 낮은 공간주파수로 표현한다.\u003c/p\u003e\n\u003cp\u003eAutoEncoder는 이러한 신경과학적 특징을 활용했다고 볼 수 있다. AutoEncoder의 Encoder는 입력 정보를 적은 정보량으로 표현하기 때문에(낮은 공간주파수에 표현하기 때문에) 불필요하거나 잡음으로 인해 훼손된 세부적인 정보를 무시하고 전체적인 특징만을 쉽게 파악할 수 있도록 한다. 이것이 AutoEncoder가 Anomaly Detection과 Noise Reduction에서 좋은 성능을 보이는 이유일 것이다.\u003c/p\u003e\n\u003ch4 id=\"reference\"\u003eReference\u003c/h4\u003e\n\u003cp\u003e\u003ca href=\"https://doi.org/10.1371/journal.pone.0076467\"\u003eJahfari S, Ridderinkhof KR, Scholte HS (2013) Spatial Frequency Information Modulates Response Inhibition and Decision-Making Processes. PLoS ONE 8(10): e76467.\u003c/a\u003e\u003c/p\u003e"])</script><script>self.__next_f.push([1,"4:[\"$\",\"div\",null,{\"className\":\"page_layout__YXtDc\",\"children\":[[\"$\",\"div\",null,{\"className\":\"GlassContainer_glass__BAl5w page_postContainer__8rQn1\",\"style\":\"$undefined\",\"children\":[\"$\",\"article\",null,{\"className\":\"$undefined\",\"children\":[[\"$\",\"header\",null,{\"className\":\"page_header__LPYYk\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"page_title__Tljh5\",\"children\":\"Autoencoder와 공간주파수\"}],[\"$\",\"div\",null,{\"className\":\"page_meta__FlrbA\",\"children\":[[\"$\",\"time\",null,{\"className\":\"$undefined\",\"children\":\"04-04-2023\"}],\"$undefined\"]}]]}],[\"$\",\"div\",null,{\"className\":\"page_content__kgYnh\",\"dangerouslySetInnerHTML\":{\"__html\":\"$d\"}}]]}]}],[\"$\",\"aside\",null,{\"className\":\"page_sidebar__vVJp_\",\"children\":[\"$\",\"nav\",null,{\"className\":\"TOC_toc__LZ8ns\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"TOC_title__k1O4v\",\"children\":\"On This Page\"}],[\"$\",\"ul\",null,{\"className\":\"TOC_list__jQuW3\",\"children\":[[\"$\",\"li\",\"0\",{\"className\":\"TOC_item__f3x9l TOC_level-4__ZEwea\",\"children\":[\"$\",\"a\",null,{\"href\":\"#reference\",\"children\":\"Reference\"}]}]]}]]}]}]]}]\na:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"SOL1 Archive\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"Personal Research Blog\"}],[\"$\",\"link\",\"4\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\"}]]\n3:null\n"])</script></body></html>