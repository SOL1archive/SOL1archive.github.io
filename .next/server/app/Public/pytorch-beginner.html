<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/_next/static/css/e7828a7281941fdd.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-7873f912334caea6.js"/><script src="/_next/static/chunks/fd9d1056-f5ca11604835b0e5.js" async=""></script><script src="/_next/static/chunks/23-e56a11d2b39fa54e.js" async=""></script><script src="/_next/static/chunks/main-app-25a28da902dbdb74.js" async=""></script><script src="/_next/static/chunks/231-c5de4feaddc0b512.js" async=""></script><script src="/_next/static/chunks/app/layout-6c2c9e9b413bbfd5.js" async=""></script><title>SOL1 Archive</title><meta name="description" content="Personal Research Blog"/><link rel="icon" href="/favicon.ico"/><script src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body><main class="min-h-screen bg-background text-foreground flex flex-col"><div class="GlassContainer_glass__BAl5w TopBar_topBar__6dGjo"><div class="TopBar_container__PF96i"><div><a class="TopBar_brandLink__ialkS" href="/">SOL1 Archive</a></div><nav class="TopBar_nav__245RK"><a class="TopBar_navLink__cN8l7 " href="/">Home</a><a class="TopBar_navLink__cN8l7 " href="/posts">Posts</a></nav><div class="TopBar_actions__aM8Lf"><a href="https://github.com/SOL1archive" target="_blank" rel="noopener noreferrer" class="TopBar_iconLink___D8mn" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-github"><path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"></path><path d="M9 18c-4.51 2-5-2-7-2"></path></svg></a><a href="https://linkedin.com/in/subinbag" target="_blank" rel="noopener noreferrer" class="TopBar_iconLink___D8mn" aria-label="LinkedIn"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-linkedin"><path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path><rect width="4" height="12" x="2" y="9"></rect><circle cx="4" cy="4" r="2"></circle></svg></a><a href="/cv/resume.pdf" download="" class="TopBar_iconLink___D8mn" aria-label="Download CV"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text"><path d="M14.5 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7.5L14.5 2z"></path><polyline points="14 2 14 8 20 8"></polyline><line x1="16" x2="8" y1="13" y2="13"></line><line x1="16" x2="8" y1="17" y2="17"></line><line x1="10" x2="8" y1="9" y2="9"></line></svg></a><button class="TopBar_iconLink___D8mn" aria-label="Toggle Dark Mode"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-sun"><circle cx="12" cy="12" r="4"></circle><path d="M12 2v2"></path><path d="M12 20v2"></path><path d="m4.93 4.93 1.41 1.41"></path><path d="m17.66 17.66 1.41 1.41"></path><path d="M2 12h2"></path><path d="M20 12h2"></path><path d="m6.34 17.66-1.41 1.41"></path><path d="m19.07 4.93-1.41 1.41"></path></svg></button></div></div></div><div class="flex-1 w-full max-w-[1200px] mx-auto p-8"><div class="page_layout__YXtDc"><div class="GlassContainer_glass__BAl5w page_postContainer__8rQn1"><article><header class="page_header__LPYYk"><h1 class="page_title__Tljh5">PyTorch를 처음 여행하는 히치하이커를 위한 안내서</h1><div class="page_meta__FlrbA"><time>12-03-2023</time></div></header><div class="page_content__kgYnh"><ul>
<li>TOC
{:toc}</li>
</ul>
<blockquote>
<p>Don't Panic</p>
</blockquote>
<p><code>PyTorch</code>는  최신 딥러닝 연구에서 가장 많이 사용되는 프레임워크다. 동적 계산 그래프를 사용하기 때문에 사용하기도 쉽고 성능도 우수하다.
하지만 무엇보다 파이토치의 큰 장점 중 하나는 PyTorch와 쉽게 연동되는 여러 라이브러리가 존재한다는 것이다. 이 중 PyTorch의 생산성을 높게 끌어올려줄 몇가지 라이브러리들이 있다.</p>
<h2 id="huggingface-transformers-시리즈">HuggingFace <code>transformers</code> 시리즈</h2>
<p><a href="https://huggingface.co/docs/transformers/index">HuggingFace transformers</a>는 파이토치의 사용성을 더 높이 끌어올려줄 대표적인 프레임워크이다.
사전 학습된(<em>Pre-trained</em>) 모델들을 쉽게 불러와 Fine-Tuning하거나 그대로 프로젝트에 사용할 수 있고, 모델들도 다양하다.</p>
<p>다른 장점은 HuggingFace에 올라와 있는 수많은 모델들을 쉽게 불러와 사용하거나 Fine-Tuning할 수 있다는 것이다.
가령 BERT의 한국어 fine-tuning 모델인 SKT의 KoBERT는 아래 코드만으로 가능하다.</p>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertTokenizer, BertModel
tokenizer = BerTokenizer.from_pretrained(<span class="hljs-string">'skt/kobert-base-v1'</span>)
model = BertModel.from_pretrained(<span class="hljs-string">'skt/kobert-base-v1'</span>)
</code></pre>
<p>뿐만 아니라 GPT-2, Stable Diffusion, Whisper과 같은 다양한 모델도 이처럼 매우 간단하게 불러와 사용이 가능하다.</p>
<h2 id="lightning-ai-pytorch-lightning">Lightning AI <code>PyTorch Lightning</code></h2>
<p>파이토치는 모델의 학습, 테스트 코드를 쉽고 간결하게 짤 수 있다는 장점이 있지만 학습, 검증, 테스트 과정을 직접 손으로 작성해야 하고, Callback을 구현하기 불편하다는 단점이 있다.
그리고 모델의 학습 코드는 바로 작성하기 때문에 코드를 수정하거나 모델의 학습과정이 복잡해질 때 코드가 스파게티화 될 수 있다는 단점이 있다.</p>
<p>이를 해결하기 위해 모델 학습, 검증, 테스트 과정을 객체지향으로 작성할 필요가 있다. 이를 가능하게 하는 것이 바로 <code>PyTorch Lightning</code>이다.</p>
<p>먼저 PyTorch Lightning의 개발자들은 다음과 같이 프레임워크를 불러올 것을 권장한다.</p>
<pre><code>import lightning as L
</code></pre>
<p>PyTorch Lightning의 구성은 Train, Validation, Test 데이터셋을 구성하는 <code>LightningDataModule</code>과 모델 순방향, 역방향 전파, 모델의 검증, 테스트 과정을 구현하는 <code>LightningModule</code>으로 구성된다.</p>
<p>먼저 <code>LightningDataModule</code>은 다음과 같이 구현한다.</p>
<pre><code class="hljs language-python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">LightningDataset</span>(L.LightningDataModule):
  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):
    <span class="hljs-built_in">super</span>().__init__()
  
  <span class="hljs-keyword">def</span> <span class="hljs-title function_">prepare_data</span>(<span class="hljs-params">self</span>):
    <span class="hljs-keyword">pass</span>
  
  <span class="hljs-keyword">def</span> <span class="hljs-title function_">setup</span>(<span class="hljs-params">self,stage=<span class="hljs-literal">None</span></span>):
    <span class="hljs-keyword">pass</span>
  
  <span class="hljs-keyword">def</span> <span class="hljs-title function_">train_dataloader</span>(<span class="hljs-params">self</span>):
    <span class="hljs-keyword">pass</span>
  
  <span class="hljs-keyword">def</span> <span class="hljs-title function_">val_dataloader</span>(<span class="hljs-params">self</span>):
    <span class="hljs-keyword">pass</span>
  
  <span class="hljs-keyword">def</span> <span class="hljs-title function_">test_dataloader</span>(<span class="hljs-params">self</span>):
    <span class="hljs-keyword">pass</span>
</code></pre>
<p><code>prepare_data</code> 함수는 하나의 전체 프로세스에서 공통적인 데이터를 준비 작업을 할 때, <code>setup</code> 함수는 각 학습, 테스트, 예측 단계에서 데이터를 준비할 때 사용한다.
그리고 나머지 <code>train_dataloader</code>, <code>val_dataloader</code>, <code>test_dataloader</code> 는 각각 학습, 검증, 테스트 단계에서 PyTorch <code>DataLoader</code>를 반환하는 함수이다.
이렇게 하나의 클래스를 통해 모든 데이터 준비과정과 <code>DataLoader</code> 생성까지 할 수 있기 때문에 코드의 재사용성이 매우 높아지고 유지 보수성도 얻을 수 있다.</p>
<p>그 후 다음과 같이 <code>LightningModule</code>을 정의한다.</p>
<pre><code class="hljs language-python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">LightningModel</span>(L.LightningModule):
  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):
    <span class="hljs-built_in">super</span>().__init__()
    
  <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,x</span>):
    <span class="hljs-keyword">pass</span>
  
  <span class="hljs-keyword">def</span> <span class="hljs-title function_">configure_optimizers</span>(<span class="hljs-params">self</span>):
    <span class="hljs-keyword">pass</span>
  
  <span class="hljs-keyword">def</span> <span class="hljs-title function_">loss_fn</span>(<span class="hljs-params">self,output,target</span>):
    <span class="hljs-keyword">pass</span> 
  
  <span class="hljs-keyword">def</span> <span class="hljs-title function_">training_step</span>(<span class="hljs-params">self</span>):
    <span class="hljs-keyword">pass</span>
  
  <span class="hljs-keyword">def</span> <span class="hljs-title function_">validation_step</span>(<span class="hljs-params">self</span>):
    <span class="hljs-keyword">pass</span>
</code></pre>
<p><code>forward</code>는 모델의 순방향 전파를 구현하는 함수로, PyTorch <code>nn.Module</code>과 동일하게 작성하면 된다.
<code>configure_optimizers</code>는 최적화 알고리즘과 학습률 스케줄러를 반환하는 함수이다.
<code>loss_fn</code>는 모델의 출력과 Ground Truth를 입력받아 오차함수를 계산하는 함수이다.
<code>traing_step</code>, <code>validation_step</code>은 모델의 학습, 검증을 구현하는 함수이다.</p>
<p>이처럼 PyTorch Lightning은 기존 PyTorch를 객체지향으로 재구성하는 것을 도와주는 라이브러리기 때문에 순수한 PyTorch 코드에서 변경하는 것도 용이하고, 코드의 유지보수성, 개선성도 좋아진다는 큰 장점을 가지고 있다.</p>
<p>추가로 PyTorch Lightning을 통해 Autoencoder, GAN(<em>Generative Adversarial Networks</em>)등의 생성 모델을 구현하는 예제는 아래 링크에서 확인할 수 있다.</p>
<blockquote>
<p><a href="https://github.com/SOL1archive/Generative-Models/tree/main">Generative Models</a></p>
</blockquote>
<p>링크에서 확인할 수 있다시피, 모델의 구현과 학습을 깔끔하고 체계적으로 구현할 수 있다.</p>
<h2 id="lightning-ai-lightning-flash">Lightning AI <code>Lightning Flash</code></h2>
<p><code>Lightning Flash</code>는 PyTorch Lightning에서 파생된 라이브러리로, 매우 간단하게 모델을 Fine-Tuning하거나 사용할 수 있다.
비록 현재는 지원이 종료되었지만 여전히 유용하게 사용할 수 있다. Speech Recognition Task와 같이 학습시키기 까다로운 Task에서 편리하게 사용할 수 있다. Speech Recognition Task에서의 예시코드는 다음과 같다.</p>
<p>우선 다음과 같이 라이브러리들을 불러온다.</p>
<pre><code class="hljs language-python"><span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> sys
<span class="hljs-keyword">import</span> pathlib

<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> flash
<span class="hljs-keyword">from</span> flash <span class="hljs-keyword">import</span> Trainer
<span class="hljs-keyword">from</span> flash.audio <span class="hljs-keyword">import</span> SpeechRecognition, SpeechRecognitionData
</code></pre>
<p><code>datamodule</code> 을 다음과 같이 불러온다.</p>
<pre><code class="hljs language-python">datamodule = SpeechRecognitionData.from_csv(
    <span class="hljs-string">'speech_files'</span>,
    <span class="hljs-string">'targets'</span>,
    train_file=<span class="hljs-string">'train_wel.csv'</span>,
    test_file=<span class="hljs-string">'test_wel.csv'</span>,
    batch_size=<span class="hljs-number">2</span>
)
</code></pre>
<p><code>model</code> 과 <code>trainer</code>를 다음과 같이 선언한다.</p>
<pre><code>model = SpeechRecognition('kresnik/wav2vec2-large-xlsr-korean')
trainer = Trainer(max_epochs=4, gpus=1)
trainer.finetune(model, datamodule=datamodule, strategy='no_freeze')
</code></pre>
<p>이제 모든 준비가 끝났다. 학습은 아래의 세 줄의 코드로 실행된다.</p>
<pre><code>datamodule = SpeechRecognitionData.from_files(predict_files=["example.wav"], batch_size=2)
predictions = trainer.predict(model, datamodule=datamodule)
print(predictions)
</code></pre>
<p>모델을 저장하는 것도 매우 간단하다.</p>
<pre><code>trainer.save_checkpoint("speech_recognition_model.pt")
</code></pre>
<p>Lightning Flash가 Speech Recognition Task에서 지원하는 모델 아키텍처는 다음과 같다. (Whisper는 지원하지 않음)</p>
<blockquote>
<p><code>Data2VecAudio</code>, <code>HuBERT</code>, <code>MCTCT</code>, <code>SEW</code>, <code>SEWD</code>, <code>UniSpeech</code>, <code>UniSpeechSat</code>, <code>Wav2Vec2</code>, <code>Wav2Vec2Conformer</code>, <code>WavLM</code></p>
</blockquote>
<h2 id="reference">Reference</h2>
<ul>
<li><a href="https://www.kaggle.com/code/shivanandmn/beginners-guide-to-pytorch-lightning/notebook">Beginner Guide to PyTorch Lightning</a></li>
<li>쿠날 사와르카르, 시밤 R 솔란키 &#x26; 아밋 조글카르. 2023. 파이토치 라이트닝으로 시작하는 딥러닝. 에이콘</li>
</ul></div></article></div><aside class="page_sidebar__vVJp_"><nav class="TOC_toc__LZ8ns"><h4 class="TOC_title__k1O4v">On This Page</h4><ul class="TOC_list__jQuW3"><li class="TOC_item__f3x9l TOC_level-2__lCxnK"><a href="#huggingface-transformers">HuggingFace `transformers` 시리즈</a></li><li class="TOC_item__f3x9l TOC_level-2__lCxnK"><a href="#lightning-ai-pytorch-lightning">Lightning AI `PyTorch Lightning`</a></li><li class="TOC_item__f3x9l TOC_level-2__lCxnK"><a href="#lightning-ai-lightning-flash">Lightning AI `Lightning Flash`</a></li><li class="TOC_item__f3x9l TOC_level-2__lCxnK"><a href="#reference">Reference</a></li></ul></nav></aside></div></div></main><script src="/_next/static/chunks/webpack-7873f912334caea6.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/css/e7828a7281941fdd.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"2:I[5751,[],\"\"]\n5:I[9275,[],\"\"]\n7:I[1343,[],\"\"]\n8:I[3889,[\"231\",\"static/chunks/231-c5de4feaddc0b512.js\",\"185\",\"static/chunks/app/layout-6c2c9e9b413bbfd5.js\"],\"default\"]\n9:I[1254,[\"231\",\"static/chunks/231-c5de4feaddc0b512.js\",\"185\",\"static/chunks/app/layout-6c2c9e9b413bbfd5.js\"],\"default\"]\nb:I[6130,[],\"\"]\n6:[\"slug\",\"Public/pytorch-beginner\",\"c\"]\nc:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/e7828a7281941fdd.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L2\",null,{\"buildId\":\"XyTXgP6qMgUjdp3ye3Nwy\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/Public/pytorch-beginner\",\"initialTree\":[\"\",{\"children\":[[\"slug\",\"Public/pytorch-beginner\",\"c\"],{\"children\":[\"__PAGE__?{\\\"slug\\\":[\\\"Public\\\",\\\"pytorch-beginner\\\"]}\",{}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[[\"slug\",\"Public/pytorch-beginner\",\"c\"],{\"children\":[\"__PAGE__\",{},[[\"$L3\",\"$L4\"],null],null]},[\"$\",\"$L5\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"$6\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L7\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"children\":[\"$\",\"main\",null,{\"className\":\"min-h-screen bg-background text-foreground flex flex-col\",\"children\":[[\"$\",\"$L8\",null,{\"gaId\":\"\"}],[\"$\",\"$L9\",null,{}],[\"$\",\"div\",null,{\"className\":\"flex-1 w-full max-w-[1200px] mx-auto p-8\",\"children\":[\"$\",\"$L5\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L7\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"notFoundStyles\":[],\"styles\":null}]}]]}]}]}],null],null],\"couldBeIntercepted\":false,\"initialHead\":[false,\"$La\"],\"globalErrorComponent\":\"$b\",\"missingSlots\":\"$Wc\"}]]\n"])</script><script>self.__next_f.push([1,"d:T2961,"])</script><script>self.__next_f.push([1,"\u003cul\u003e\n\u003cli\u003eTOC\n{:toc}\u003c/li\u003e\n\u003c/ul\u003e\n\u003cblockquote\u003e\n\u003cp\u003eDon't Panic\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003ccode\u003ePyTorch\u003c/code\u003e는  최신 딥러닝 연구에서 가장 많이 사용되는 프레임워크다. 동적 계산 그래프를 사용하기 때문에 사용하기도 쉽고 성능도 우수하다.\n하지만 무엇보다 파이토치의 큰 장점 중 하나는 PyTorch와 쉽게 연동되는 여러 라이브러리가 존재한다는 것이다. 이 중 PyTorch의 생산성을 높게 끌어올려줄 몇가지 라이브러리들이 있다.\u003c/p\u003e\n\u003ch2 id=\"huggingface-transformers-시리즈\"\u003eHuggingFace \u003ccode\u003etransformers\u003c/code\u003e 시리즈\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://huggingface.co/docs/transformers/index\"\u003eHuggingFace transformers\u003c/a\u003e는 파이토치의 사용성을 더 높이 끌어올려줄 대표적인 프레임워크이다.\n사전 학습된(\u003cem\u003ePre-trained\u003c/em\u003e) 모델들을 쉽게 불러와 Fine-Tuning하거나 그대로 프로젝트에 사용할 수 있고, 모델들도 다양하다.\u003c/p\u003e\n\u003cp\u003e다른 장점은 HuggingFace에 올라와 있는 수많은 모델들을 쉽게 불러와 사용하거나 Fine-Tuning할 수 있다는 것이다.\n가령 BERT의 한국어 fine-tuning 모델인 SKT의 KoBERT는 아래 코드만으로 가능하다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e transformers \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e BertTokenizer, BertModel\ntokenizer = BerTokenizer.from_pretrained(\u003cspan class=\"hljs-string\"\u003e'skt/kobert-base-v1'\u003c/span\u003e)\nmodel = BertModel.from_pretrained(\u003cspan class=\"hljs-string\"\u003e'skt/kobert-base-v1'\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e뿐만 아니라 GPT-2, Stable Diffusion, Whisper과 같은 다양한 모델도 이처럼 매우 간단하게 불러와 사용이 가능하다.\u003c/p\u003e\n\u003ch2 id=\"lightning-ai-pytorch-lightning\"\u003eLightning AI \u003ccode\u003ePyTorch Lightning\u003c/code\u003e\u003c/h2\u003e\n\u003cp\u003e파이토치는 모델의 학습, 테스트 코드를 쉽고 간결하게 짤 수 있다는 장점이 있지만 학습, 검증, 테스트 과정을 직접 손으로 작성해야 하고, Callback을 구현하기 불편하다는 단점이 있다.\n그리고 모델의 학습 코드는 바로 작성하기 때문에 코드를 수정하거나 모델의 학습과정이 복잡해질 때 코드가 스파게티화 될 수 있다는 단점이 있다.\u003c/p\u003e\n\u003cp\u003e이를 해결하기 위해 모델 학습, 검증, 테스트 과정을 객체지향으로 작성할 필요가 있다. 이를 가능하게 하는 것이 바로 \u003ccode\u003ePyTorch Lightning\u003c/code\u003e이다.\u003c/p\u003e\n\u003cp\u003e먼저 PyTorch Lightning의 개발자들은 다음과 같이 프레임워크를 불러올 것을 권장한다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eimport lightning as L\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ePyTorch Lightning의 구성은 Train, Validation, Test 데이터셋을 구성하는 \u003ccode\u003eLightningDataModule\u003c/code\u003e과 모델 순방향, 역방향 전파, 모델의 검증, 테스트 과정을 구현하는 \u003ccode\u003eLightningModule\u003c/code\u003e으로 구성된다.\u003c/p\u003e\n\u003cp\u003e먼저 \u003ccode\u003eLightningDataModule\u003c/code\u003e은 다음과 같이 구현한다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003eclass\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eLightningDataset\u003c/span\u003e(L.LightningDataModule):\n  \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003e__init__\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself\u003c/span\u003e):\n    \u003cspan class=\"hljs-built_in\"\u003esuper\u003c/span\u003e().__init__()\n  \n  \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eprepare_data\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself\u003c/span\u003e):\n    \u003cspan class=\"hljs-keyword\"\u003epass\u003c/span\u003e\n  \n  \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003esetup\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself,stage=\u003cspan class=\"hljs-literal\"\u003eNone\u003c/span\u003e\u003c/span\u003e):\n    \u003cspan class=\"hljs-keyword\"\u003epass\u003c/span\u003e\n  \n  \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003etrain_dataloader\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself\u003c/span\u003e):\n    \u003cspan class=\"hljs-keyword\"\u003epass\u003c/span\u003e\n  \n  \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eval_dataloader\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself\u003c/span\u003e):\n    \u003cspan class=\"hljs-keyword\"\u003epass\u003c/span\u003e\n  \n  \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003etest_dataloader\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself\u003c/span\u003e):\n    \u003cspan class=\"hljs-keyword\"\u003epass\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003ccode\u003eprepare_data\u003c/code\u003e 함수는 하나의 전체 프로세스에서 공통적인 데이터를 준비 작업을 할 때, \u003ccode\u003esetup\u003c/code\u003e 함수는 각 학습, 테스트, 예측 단계에서 데이터를 준비할 때 사용한다.\n그리고 나머지 \u003ccode\u003etrain_dataloader\u003c/code\u003e, \u003ccode\u003eval_dataloader\u003c/code\u003e, \u003ccode\u003etest_dataloader\u003c/code\u003e 는 각각 학습, 검증, 테스트 단계에서 PyTorch \u003ccode\u003eDataLoader\u003c/code\u003e를 반환하는 함수이다.\n이렇게 하나의 클래스를 통해 모든 데이터 준비과정과 \u003ccode\u003eDataLoader\u003c/code\u003e 생성까지 할 수 있기 때문에 코드의 재사용성이 매우 높아지고 유지 보수성도 얻을 수 있다.\u003c/p\u003e\n\u003cp\u003e그 후 다음과 같이 \u003ccode\u003eLightningModule\u003c/code\u003e을 정의한다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003eclass\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eLightningModel\u003c/span\u003e(L.LightningModule):\n  \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003e__init__\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself\u003c/span\u003e):\n    \u003cspan class=\"hljs-built_in\"\u003esuper\u003c/span\u003e().__init__()\n    \n  \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eforward\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself,x\u003c/span\u003e):\n    \u003cspan class=\"hljs-keyword\"\u003epass\u003c/span\u003e\n  \n  \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003econfigure_optimizers\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself\u003c/span\u003e):\n    \u003cspan class=\"hljs-keyword\"\u003epass\u003c/span\u003e\n  \n  \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eloss_fn\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself,output,target\u003c/span\u003e):\n    \u003cspan class=\"hljs-keyword\"\u003epass\u003c/span\u003e \n  \n  \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003etraining_step\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself\u003c/span\u003e):\n    \u003cspan class=\"hljs-keyword\"\u003epass\u003c/span\u003e\n  \n  \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003evalidation_step\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself\u003c/span\u003e):\n    \u003cspan class=\"hljs-keyword\"\u003epass\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003ccode\u003eforward\u003c/code\u003e는 모델의 순방향 전파를 구현하는 함수로, PyTorch \u003ccode\u003enn.Module\u003c/code\u003e과 동일하게 작성하면 된다.\n\u003ccode\u003econfigure_optimizers\u003c/code\u003e는 최적화 알고리즘과 학습률 스케줄러를 반환하는 함수이다.\n\u003ccode\u003eloss_fn\u003c/code\u003e는 모델의 출력과 Ground Truth를 입력받아 오차함수를 계산하는 함수이다.\n\u003ccode\u003etraing_step\u003c/code\u003e, \u003ccode\u003evalidation_step\u003c/code\u003e은 모델의 학습, 검증을 구현하는 함수이다.\u003c/p\u003e\n\u003cp\u003e이처럼 PyTorch Lightning은 기존 PyTorch를 객체지향으로 재구성하는 것을 도와주는 라이브러리기 때문에 순수한 PyTorch 코드에서 변경하는 것도 용이하고, 코드의 유지보수성, 개선성도 좋아진다는 큰 장점을 가지고 있다.\u003c/p\u003e\n\u003cp\u003e추가로 PyTorch Lightning을 통해 Autoencoder, GAN(\u003cem\u003eGenerative Adversarial Networks\u003c/em\u003e)등의 생성 모델을 구현하는 예제는 아래 링크에서 확인할 수 있다.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/SOL1archive/Generative-Models/tree/main\"\u003eGenerative Models\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e링크에서 확인할 수 있다시피, 모델의 구현과 학습을 깔끔하고 체계적으로 구현할 수 있다.\u003c/p\u003e\n\u003ch2 id=\"lightning-ai-lightning-flash\"\u003eLightning AI \u003ccode\u003eLightning Flash\u003c/code\u003e\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eLightning Flash\u003c/code\u003e는 PyTorch Lightning에서 파생된 라이브러리로, 매우 간단하게 모델을 Fine-Tuning하거나 사용할 수 있다.\n비록 현재는 지원이 종료되었지만 여전히 유용하게 사용할 수 있다. Speech Recognition Task와 같이 학습시키기 까다로운 Task에서 편리하게 사용할 수 있다. Speech Recognition Task에서의 예시코드는 다음과 같다.\u003c/p\u003e\n\u003cp\u003e우선 다음과 같이 라이브러리들을 불러온다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e os\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e sys\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e pathlib\n\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e torch\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e flash\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e flash \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e Trainer\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e flash.audio \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e SpeechRecognition, SpeechRecognitionData\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003ccode\u003edatamodule\u003c/code\u003e 을 다음과 같이 불러온다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003edatamodule = SpeechRecognitionData.from_csv(\n    \u003cspan class=\"hljs-string\"\u003e'speech_files'\u003c/span\u003e,\n    \u003cspan class=\"hljs-string\"\u003e'targets'\u003c/span\u003e,\n    train_file=\u003cspan class=\"hljs-string\"\u003e'train_wel.csv'\u003c/span\u003e,\n    test_file=\u003cspan class=\"hljs-string\"\u003e'test_wel.csv'\u003c/span\u003e,\n    batch_size=\u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e\n)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003ccode\u003emodel\u003c/code\u003e 과 \u003ccode\u003etrainer\u003c/code\u003e를 다음과 같이 선언한다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003emodel = SpeechRecognition('kresnik/wav2vec2-large-xlsr-korean')\ntrainer = Trainer(max_epochs=4, gpus=1)\ntrainer.finetune(model, datamodule=datamodule, strategy='no_freeze')\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e이제 모든 준비가 끝났다. 학습은 아래의 세 줄의 코드로 실행된다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edatamodule = SpeechRecognitionData.from_files(predict_files=[\"example.wav\"], batch_size=2)\npredictions = trainer.predict(model, datamodule=datamodule)\nprint(predictions)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e모델을 저장하는 것도 매우 간단하다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003etrainer.save_checkpoint(\"speech_recognition_model.pt\")\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eLightning Flash가 Speech Recognition Task에서 지원하는 모델 아키텍처는 다음과 같다. (Whisper는 지원하지 않음)\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003ccode\u003eData2VecAudio\u003c/code\u003e, \u003ccode\u003eHuBERT\u003c/code\u003e, \u003ccode\u003eMCTCT\u003c/code\u003e, \u003ccode\u003eSEW\u003c/code\u003e, \u003ccode\u003eSEWD\u003c/code\u003e, \u003ccode\u003eUniSpeech\u003c/code\u003e, \u003ccode\u003eUniSpeechSat\u003c/code\u003e, \u003ccode\u003eWav2Vec2\u003c/code\u003e, \u003ccode\u003eWav2Vec2Conformer\u003c/code\u003e, \u003ccode\u003eWavLM\u003c/code\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2 id=\"reference\"\u003eReference\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.kaggle.com/code/shivanandmn/beginners-guide-to-pytorch-lightning/notebook\"\u003eBeginner Guide to PyTorch Lightning\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e쿠날 사와르카르, 시밤 R 솔란키 \u0026#x26; 아밋 조글카르. 2023. 파이토치 라이트닝으로 시작하는 딥러닝. 에이콘\u003c/li\u003e\n\u003c/ul\u003e"])</script><script>self.__next_f.push([1,"4:[\"$\",\"div\",null,{\"className\":\"page_layout__YXtDc\",\"children\":[[\"$\",\"div\",null,{\"className\":\"GlassContainer_glass__BAl5w page_postContainer__8rQn1\",\"style\":\"$undefined\",\"children\":[\"$\",\"article\",null,{\"className\":\"$undefined\",\"children\":[[\"$\",\"header\",null,{\"className\":\"page_header__LPYYk\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"page_title__Tljh5\",\"children\":\"PyTorch를 처음 여행하는 히치하이커를 위한 안내서\"}],[\"$\",\"div\",null,{\"className\":\"page_meta__FlrbA\",\"children\":[[\"$\",\"time\",null,{\"className\":\"$undefined\",\"children\":\"12-03-2023\"}],\"$undefined\"]}]]}],[\"$\",\"div\",null,{\"className\":\"page_content__kgYnh\",\"dangerouslySetInnerHTML\":{\"__html\":\"$d\"}}]]}]}],[\"$\",\"aside\",null,{\"className\":\"page_sidebar__vVJp_\",\"children\":[\"$\",\"nav\",null,{\"className\":\"TOC_toc__LZ8ns\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"TOC_title__k1O4v\",\"children\":\"On This Page\"}],[\"$\",\"ul\",null,{\"className\":\"TOC_list__jQuW3\",\"children\":[[\"$\",\"li\",\"0\",{\"className\":\"TOC_item__f3x9l TOC_level-2__lCxnK\",\"children\":[\"$\",\"a\",null,{\"href\":\"#huggingface-transformers\",\"children\":\"HuggingFace `transformers` 시리즈\"}]}],[\"$\",\"li\",\"1\",{\"className\":\"TOC_item__f3x9l TOC_level-2__lCxnK\",\"children\":[\"$\",\"a\",null,{\"href\":\"#lightning-ai-pytorch-lightning\",\"children\":\"Lightning AI `PyTorch Lightning`\"}]}],[\"$\",\"li\",\"2\",{\"className\":\"TOC_item__f3x9l TOC_level-2__lCxnK\",\"children\":[\"$\",\"a\",null,{\"href\":\"#lightning-ai-lightning-flash\",\"children\":\"Lightning AI `Lightning Flash`\"}]}],[\"$\",\"li\",\"3\",{\"className\":\"TOC_item__f3x9l TOC_level-2__lCxnK\",\"children\":[\"$\",\"a\",null,{\"href\":\"#reference\",\"children\":\"Reference\"}]}]]}]]}]}]]}]\na:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"SOL1 Archive\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"Personal Research Blog\"}],[\"$\",\"link\",\"4\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\"}]]\n3:null\n"])</script></body></html>